{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvYTvRSKp9wdNpRv23HP8a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","\n","########################################\n","# You can define whatever classes if needed\n","########################################\n","\n","class ResBlock(nn.Module):\n","    def __init__(self, in_channel, out_channel, downsample=False):\n","        super(ResBlock, self).__init__()\n","        self.in_channel = in_channel\n","        self.out_channel = out_channel\n","        self.downsample = downsample\n","        self.build_layer()\n","    \n","    def build_layer(self):\n","        self.batchNorm_in = nn.BatchNorm2d(self.in_channel, )\n","        self.relu = nn.ReLU()\n","        self.conv_1 = nn.Conv2d(self.in_channel, self.out_channel, kernel_size=3, stride=1, padding=1)\n","        self.conv_downsample = nn.Conv2d(self.in_channel, self.out_channel, kernel_size=3, stride=2, padding=1)\n","        self.conv_pool = nn.Conv2d(self.in_channel, self.out_channel, kernel_size=1, stride=2)\n","        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.batchNorm_out = nn.BatchNorm2d(self.out_channel)\n","        self.conv_2 = nn.Conv2d(self.out_channel, self.out_channel, kernel_size=3, stride=1, padding=1)\n","\n","    def residual(self, x):\n","        x = self.batchNorm_in(x)\n","        x = self.relu(x)\n","        if self.downsample:\n","            x = self.conv_downsample(x)\n","        else:\n","            x = self.conv_1(x)\n","        x = self.batchNorm_out(x)\n","        x = self.conv_2(x)\n","        return x\n","  \n","    def shortcut(self, x):\n","        if self.downsample:\n","            x = self.batchNorm_in(x)\n","            x = self.relu(x)\n","            ## Maxpooling\n","            x = self.maxpool(x)\n","            y = torch.zeros_like(x)\n","            x = torch.cat([x,y],1)\n","        return x\n","\n","    def forward(self, x):\n","        return self.residual(x) + self.shortcut(x)\n","\n","class IdentityResNet(nn.Module):\n","    \n","    # __init__ takes 4 parameters\n","    # nblk_stage1: number of blocks in stage 1, nblk_stage2.. similar\n","    def __init__(self, nblk_stage1, nblk_stage2, nblk_stage3, nblk_stage4):\n","        super(IdentityResNet, self).__init__()\n","    ########################################\n","    # Implement the network\n","    # You can declare whatever variables\n","    ########################################\n","        self.n1 = nblk_stage1\n","        self.n2 = nblk_stage2\n","        self.n3 = nblk_stage3\n","        self.n4 = nblk_stage4\n","        self.build_layer()\n","    \n","    def build_layer(self):\n","        layers = (nn.ModuleList() for i in range(4))\n","        self.layers_stage1, self.layers_stage2, self.layers_stage3, self.layers_stage4 = layers\n","        self.conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n","        # stage1\n","        for i in range(self.n1):\n","            self.layers_stage1.append(ResBlock(64, 64))\n","        # stage2\n","        self.layers_stage2.append(ResBlock(64, 128, downsample=True))\n","        for i in range(self.n2-1):\n","            self.layers_stage2.append(ResBlock(128, 128))\n","        # stage3\n","        self.layers_stage3.append(ResBlock(128,256, downsample=True))\n","        for i in range(self.n3-1):\n","            self.layers_stage3.append(ResBlock(256, 256))\n","        # stage4\n","        self.layers_stage4.append(ResBlock(256,512, downsample=True))\n","        for i in range(self.n4-1):\n","            self.layers_stage4.append(ResBlock(512,512))\n","        self.fcLayer = nn.Linear(512,10)\n","    ########################################\n","    # You can define whatever methods\n","    ########################################\n","    \n","    def forward(self, x):\n","        ########################################\n","        # Implement the network\n","        # You can declare or define whatever variables or methods\n","        ########################################\n","        x = self.conv(x)\n","        for layer in self.layers_stage1:\n","            x = layer(x)\n","        for layer in self.layers_stage2:\n","            x = layer(x)\n","        for layer in self.layers_stage3:\n","            x = layer(x)\n","        for layer in self.layers_stage4:\n","            x = layer(x)\n","        out = F.avg_pool2d(x, 4)\n","        out = out.reshape([-1, 512])\n","        out = self.fcLayer(out)\n","        return out\n","\n","########################################\n","# Q1. set device\n","# First, check availability of GPU.\n","# If available, set dev to \"cuda:0\";\n","# otherwise set dev to \"cpu\"\n","########################################\n","dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('current device: ', dev)\n","\n","\n","########################################\n","# data preparation: CIFAR10\n","########################################\n","\n","########################################\n","# Q2. set batch size\n","# set batch size for training data\n","########################################\n","batch_size = 4\n","\n","# preprocessing\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","# load training data\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True)\n","\n","# load test data\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n","                                         shuffle=False)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","\n","# define network\n","net = IdentityResNet(nblk_stage1=2, nblk_stage2=2,\n","                     nblk_stage3=2, nblk_stage4=2)\n","\n","########################################\n","# Q3. load model to GPU\n","# Complete below to load model to GPU\n","########################################\n","net = net.to(dev)\n","\n","\n","# set loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","########################################\n","# Q4. optimizer\n","# Complete below to use SGD with momentum (alpha= 0.9)\n","# set proper learning rate\n","########################################\n","optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n","\n","# start training\n","t_start = time.time()\n","\n","for epoch in range(5):  # loop over the dataset multiple times\n","    \n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(dev), data[1].to(dev)\n","        \n","        ########################################\n","        # Q5. make sure gradients are zero!\n","        # zero the parameter gradients\n","        ########################################\n","        optimizer.zero_grad()\n","        \n","        ########################################\n","        # Q6. perform forward pass\n","        ########################################\n","        outputs = net(inputs)\n","        \n","        # set loss\n","        loss = criterion(outputs, labels)\n","        \n","        ########################################\n","        # Q7. perform backprop\n","        ########################################\n","        loss.backward()\n","        \n","        ########################################\n","        # Q8. take a SGD step\n","        ########################################\n","        optimizer.step()\n","        \n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 2000 == 1999:    # print every 2000 mini-batches\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n","            running_loss = 0.0\n","            t_end = time.time()\n","            print('elapsed:', t_end-t_start, ' sec')\n","            t_start = t_end\n","\n","print('Finished Training')\n","\n","\n","# now testing\n","class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","########################################\n","# Q9. complete below\n","# when testing, computation is done without building graphs\n","########################################\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(dev), data[1].to(dev)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs, 1)\n","        c = (predicted == labels).squeeze()\n","        for i in range(4):\n","            label = labels[i]\n","            class_correct[label] += c[i].item()\n","            class_total[label] += 1\n","\n","# per-class accuracy\n","for i in range(10):\n","    print('Accuracy of %5s' %(classes[i]), ': ',\n","          100 * class_correct[i] / class_total[i],'%')\n","\n","# overall accuracy\n","print('Overall Accurracy: ', (sum(class_correct)/sum(class_total))*100, '%')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyCkxZFttrYo","executionInfo":{"status":"ok","timestamp":1670574917288,"user_tz":-540,"elapsed":808934,"user":{"displayName":"조영준","userId":"02170786370807215872"}},"outputId":"22a511f0-f30c-433d-9f02-28d66deced28"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["current device:  cuda:0\n","Files already downloaded and verified\n","Files already downloaded and verified\n","[1,  2000] loss: 1.784\n","elapsed: 25.292720317840576  sec\n","[1,  4000] loss: 1.375\n","elapsed: 25.281880378723145  sec\n","[1,  6000] loss: 1.216\n","elapsed: 25.339436769485474  sec\n","[1,  8000] loss: 1.099\n","elapsed: 25.284958839416504  sec\n","[1, 10000] loss: 1.030\n","elapsed: 25.537842988967896  sec\n","[1, 12000] loss: 0.954\n","elapsed: 26.525699853897095  sec\n","[2,  2000] loss: 0.841\n","elapsed: 31.55537438392639  sec\n","[2,  4000] loss: 0.841\n","elapsed: 25.379701614379883  sec\n","[2,  6000] loss: 0.805\n","elapsed: 25.255536794662476  sec\n","[2,  8000] loss: 0.782\n","elapsed: 25.22091507911682  sec\n","[2, 10000] loss: 0.743\n","elapsed: 25.26669478416443  sec\n","[2, 12000] loss: 0.733\n","elapsed: 25.34852695465088  sec\n","[3,  2000] loss: 0.618\n","elapsed: 31.531318426132202  sec\n","[3,  4000] loss: 0.634\n","elapsed: 25.43999481201172  sec\n","[3,  6000] loss: 0.643\n","elapsed: 25.263705015182495  sec\n","[3,  8000] loss: 0.620\n","elapsed: 25.220458269119263  sec\n","[3, 10000] loss: 0.617\n","elapsed: 25.46392846107483  sec\n","[3, 12000] loss: 0.611\n","elapsed: 26.11989402770996  sec\n","[4,  2000] loss: 0.490\n","elapsed: 31.458656549453735  sec\n","[4,  4000] loss: 0.511\n","elapsed: 25.335023880004883  sec\n","[4,  6000] loss: 0.520\n","elapsed: 25.27587652206421  sec\n","[4,  8000] loss: 0.523\n","elapsed: 25.183733701705933  sec\n","[4, 10000] loss: 0.524\n","elapsed: 25.261402368545532  sec\n","[4, 12000] loss: 0.507\n","elapsed: 25.293094396591187  sec\n","[5,  2000] loss: 0.386\n","elapsed: 31.516677379608154  sec\n","[5,  4000] loss: 0.403\n","elapsed: 25.23023748397827  sec\n","[5,  6000] loss: 0.442\n","elapsed: 25.186437129974365  sec\n","[5,  8000] loss: 0.413\n","elapsed: 25.6229510307312  sec\n","[5, 10000] loss: 0.441\n","elapsed: 25.97152853012085  sec\n","[5, 12000] loss: 0.431\n","elapsed: 25.198337078094482  sec\n","Finished Training\n","Accuracy of plane :  90.0 %\n","Accuracy of   car :  82.3 %\n","Accuracy of  bird :  68.9 %\n","Accuracy of   cat :  70.4 %\n","Accuracy of  deer :  80.6 %\n","Accuracy of   dog :  66.1 %\n","Accuracy of  frog :  83.1 %\n","Accuracy of horse :  82.3 %\n","Accuracy of  ship :  84.3 %\n","Accuracy of truck :  89.0 %\n","Overall Accurracy:  79.7 %\n"]}]}]}