{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112710,"status":"ok","timestamp":1671748658704,"user":{"displayName":"조영준","userId":"02170786370807215872"},"user_tz":-540},"id":"72xJP5gzfvBl","outputId":"ff73649c-80d1-43cd-f828-4b8169977ce1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchtext==0.13.0\n","  Downloading torchtext-0.13.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.13.0) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.13.0) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.13.0) (4.64.1)\n","Collecting torch==1.12.0\n","  Downloading torch-1.12.0-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n","\u001b[K     |████████████████████████████████| 776.3 MB 11 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.0->torchtext==0.13.0) (4.4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.13.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.13.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.13.0) (2022.12.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.13.0) (3.0.4)\n","Installing collected packages: torch, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.14.0\n","    Uninstalling torchtext-0.14.0:\n","      Successfully uninstalled torchtext-0.14.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.12.0 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.12.0 torchtext-0.13.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchdata==0.4.0\n","  Downloading torchdata-0.4.0-cp38-cp38-manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 29.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.8/dist-packages (from torchdata==0.4.0) (1.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchdata==0.4.0) (2.23.0)\n","Collecting portalocker>=2.0.0\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Collecting urllib3>=1.25\n","  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 72.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.0->torchdata==0.4.0) (4.4.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.4.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.4.0) (2022.12.7)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 78.5 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchdata==0.4.0) (3.0.4)\n","Installing collected packages: urllib3, portalocker, torchdata\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed portalocker-2.6.0 torchdata-0.4.0 urllib3-1.25.11\n"]}],"source":["!pip install torchtext==0.13.0\n","!pip install torchdata==0.4.0"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22494,"status":"ok","timestamp":1671748695532,"user":{"displayName":"조영준","userId":"02170786370807215872"},"user_tz":-540},"id":"8QL9zdpNhkii","outputId":"b13fe634-037c-4ff1-d75b-22614e905843"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671748697297,"user":{"displayName":"조영준","userId":"02170786370807215872"},"user_tz":-540},"id":"5TyXV2GshkvI","outputId":"98ca697e-f2fa-49ae-da71-28fd12f3559c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DL\n"]}],"source":["%cd /content/drive/MyDrive/DL"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42Ppqafxf-fF","executionInfo":{"status":"ok","timestamp":1671749752900,"user_tz":-540,"elapsed":1050695,"user":{"displayName":"조영준","userId":"02170786370807215872"}},"outputId":"bf75c086-d975-4595-84a7-f7d7d6ba524a"},"outputs":[{"output_type":"stream","name":"stdout","text":["negative\n","i think its time for seagal to go quietly into the night . what i have just seen makes all his direct to video releases in the last few years look like his early 90 ' s smash hits in comparison . a secret bio lab is making a new kind of drug that <UNK> up a human ' s adrenaline system to the point where they become psychopathic killers or something . somehow seagal is supposed to stop the infection or its the end of the world . . . or something . seagal also went through hit <UNK> like <UNK> , every time i look up he was commanding a new face so it kinda got hard to follow character development as well i know steven ' s <UNK> prevent him from yelling at the top of his lungs but even so why is he constantly being dubbed by people who sound nothing like him ? usually the films plot and action sequences can save it from being a total waste of time but this was not even close . like i said , it was more of a horror movie with a lot of blood and <UNK> stabbing rather than straight up fighting . the problem was it wasn ' t really scary and seagal looked completely out of place because the infected people were supposed to have speed of light movement yet the 40 year old <UNK> <UNK> seagal killed them all <UNK> ? i guess the lone highlight of the movie was the first 20 minutes where the new recruits ask seagal to come to the strip club with them . 2 out of 10\n","\n","negative\n","the <UNK> for tree of <UNK> try to pass it off as a sort of allegory for a fairy tale with actual meaning , then immediately start raving about the animation . i should have known what that meant . the main character , <UNK> , is a good example of the whole movie ' s problem . one minute , <UNK> is a humble hero in search of himself , the next a violent psycho with an unhealthy fixation on a girl he once took care of . like all of the characters in the movie , <UNK> is poorly defined . you do not bond with the characters at all , although <UNK> has acquired a couple of fan girls . it seems that the writer was more interested in <UNK> all the drama and complexity he could into this movie than actually exploring his characters ' motivations and personalities . new , useless story lines were being introduced in the last fifteen minutes of the movie . the writer seriously needed to <UNK> his story . perhaps he was trying to be epic , but it was simply too much information for a two-hour movie . however i can ' t help but wonder if a plot with so many dimensions and characters would have been better suited for a tv series or graphic novel . in the last five minutes of the movie , i simply could not endure the sheer lack of quality any longer and began laughing at how contrived the characters , the relationships , and the whole plot was . i touched my companion and he started cracking up too , as did a young man seated behind us . we tried so hard to control ourselves , but we simply could not take the terrible quality of this movie . on the bright side , the animation is incredible and viewers will find themselves admiring the lush backgrounds and charming character designs . the animation almost guides you when you don ' t care about the characters , it tells you how to feel .\n","\n","positive\n","i understand that paramount wanted to film this with the rodgers and hart score , but couldn ' t work out the copyright problems , so burke and van <UNK> who wrote the between them the most songs for bing crosby contributed a very nice score . i read leonard maltin saying that this movie , fit crosby like a glove and i couldn ' t have put it better . no , it ' s not mark twain ' s satire , it ' s a bing crosby film and in 1949 crosby was the most <UNK> star in hollywood . for once paramount used technicolor and rhonda fleming was never <UNK> on the screen . this was a woman that technicolor was invented for . william <UNK> ' s brooklyn origins kinda stand out , but it ' s to a good comic effect . the trio of crosby , <UNK> , and sir cedric hardwicke have a rollicking good time with busy doing nothing . bing has one of his patented upbeat philosophical numbers with if you <UNK> your toe on the moon . the third song he sings once and for always by himself and with rhonda fleming . that song was nominated for best song , but lost to baby it ' s cold outside . nice also that bing managed to record the score for <UNK> with rhonda fleming and <UNK> and hardwicke . one thing i like about this film is that it shows crosby ' s comic talents without bob hope . i like the road pictures , but bing was a comic talent onto himself and this film better demonstrates than any other . this is crosby at the top of his game .\n","\n","negative\n","ever since the <UNK> universe made acquaintance with a guy named george a . romero , the word zombie automatically gets associated with <UNK> horror images and non-stop acting sequences . it ' s safe to say that his night of the living dead formed the zombie movie as we know it now . yet , in the earliest years of cinema , the premise of <UNK> corpses was merely used in slow , nearly <UNK> psychological thrillers . jacques tourneur ' s i walked with a zombie is a perfect example and so is white zombie , starring bela lugosi . this revolt of the zombies could have been another example but unfortunately it ' s a failure over the entire line and easily one of the most tedious movies i ever saw . dreadful acting , a very poorly written screenplay and a complete lack of atmosphere and tension ! the film only lasts 65 minutes and yet the first half hour is entirely wasted on stupid <UNK> intrigues and unexciting monologues . the setting in the legendary cambodian city of <UNK> surely could have resulted in a more compelling story but all we ever see are interior shots . the lead actress ( dorothy stone , textbook blonde with curly hair and an ugly nose ) irritated me enormously and i kept hoping a ravenous undead would suddenly appear out of nowhere to devour her . unlucky again . if you manage to struggle yourself through 60 <UNK> minutes , you ' ll be rewarded with a fairly decent finale . still , this is far too little to give this film a positive rating , let alone a recommendation . avoid ! this is the type of movie you should only see in case you already saw everything else .\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["\tAccuracy: 0.517\n","Epoch: 01 | Time: 0m 31s\n","\tTrain Loss: 0.694 | Val. Loss: 0.693\n","\tAccuracy: 0.523\n","Epoch: 02 | Time: 0m 31s\n","\tTrain Loss: 0.694 | Val. Loss: 0.692\n","\tAccuracy: 0.532\n","Epoch: 03 | Time: 0m 31s\n","\tTrain Loss: 0.692 | Val. Loss: 0.690\n","\tAccuracy: 0.576\n","Epoch: 04 | Time: 0m 31s\n","\tTrain Loss: 0.689 | Val. Loss: 0.684\n","\tAccuracy: 0.611\n","Epoch: 05 | Time: 0m 31s\n","\tTrain Loss: 0.681 | Val. Loss: 0.668\n","\tAccuracy: 0.686\n","Epoch: 06 | Time: 0m 32s\n","\tTrain Loss: 0.659 | Val. Loss: 0.628\n","\tAccuracy: 0.753\n","Epoch: 07 | Time: 0m 32s\n","\tTrain Loss: 0.611 | Val. Loss: 0.554\n","\tAccuracy: 0.771\n","Epoch: 08 | Time: 0m 32s\n","\tTrain Loss: 0.544 | Val. Loss: 0.489\n","\tAccuracy: 0.800\n","Epoch: 09 | Time: 0m 32s\n","\tTrain Loss: 0.487 | Val. Loss: 0.436\n","\tAccuracy: 0.824\n","Epoch: 10 | Time: 0m 32s\n","\tTrain Loss: 0.453 | Val. Loss: 0.399\n","\tAccuracy: 0.830\n","Epoch: 11 | Time: 0m 32s\n","\tTrain Loss: 0.415 | Val. Loss: 0.381\n","\tAccuracy: 0.841\n","Epoch: 12 | Time: 0m 32s\n","\tTrain Loss: 0.387 | Val. Loss: 0.370\n","\tAccuracy: 0.842\n","Epoch: 13 | Time: 0m 32s\n","\tTrain Loss: 0.368 | Val. Loss: 0.349\n","\tAccuracy: 0.847\n","Epoch: 14 | Time: 0m 32s\n","\tTrain Loss: 0.353 | Val. Loss: 0.353\n","\tAccuracy: 0.854\n","Epoch: 15 | Time: 0m 32s\n","\tTrain Loss: 0.349 | Val. Loss: 0.334\n","\tAccuracy: 0.859\n","Epoch: 16 | Time: 0m 32s\n","\tTrain Loss: 0.338 | Val. Loss: 0.333\n","\tAccuracy: 0.859\n","Epoch: 17 | Time: 0m 32s\n","\tTrain Loss: 0.320 | Val. Loss: 0.324\n","\tAccuracy: 0.862\n","Epoch: 18 | Time: 0m 32s\n","\tTrain Loss: 0.314 | Val. Loss: 0.323\n","\tAccuracy: 0.863\n","Epoch: 19 | Time: 0m 32s\n","\tTrain Loss: 0.308 | Val. Loss: 0.327\n","\tAccuracy: 0.865\n","Epoch: 20 | Time: 0m 32s\n","\tTrain Loss: 0.296 | Val. Loss: 0.325\n","\tAccuracy: 0.863\n","Epoch: 21 | Time: 0m 32s\n","\tTrain Loss: 0.286 | Val. Loss: 0.324\n","\tAccuracy: 0.871\n","Epoch: 22 | Time: 0m 32s\n","\tTrain Loss: 0.287 | Val. Loss: 0.318\n","\tAccuracy: 0.874\n","Epoch: 23 | Time: 0m 32s\n","\tTrain Loss: 0.280 | Val. Loss: 0.316\n","\tAccuracy: 0.870\n","Epoch: 24 | Time: 0m 32s\n","\tTrain Loss: 0.275 | Val. Loss: 0.315\n","\tAccuracy: 0.871\n","Epoch: 25 | Time: 0m 32s\n","\tTrain Loss: 0.268 | Val. Loss: 0.318\n","\tAccuracy: 0.873\n","Epoch: 26 | Time: 0m 32s\n","\tTrain Loss: 0.265 | Val. Loss: 0.312\n","\tAccuracy: 0.871\n","Epoch: 27 | Time: 0m 32s\n","\tTrain Loss: 0.256 | Val. Loss: 0.313\n","\tAccuracy: 0.870\n","Epoch: 28 | Time: 0m 32s\n","\tTrain Loss: 0.252 | Val. Loss: 0.310\n","\tAccuracy: 0.868\n","Epoch: 29 | Time: 0m 32s\n","\tTrain Loss: 0.250 | Val. Loss: 0.307\n","\tAccuracy: 0.880\n","Epoch: 30 | Time: 0m 32s\n","\tTrain Loss: 0.245 | Val. Loss: 0.310\n","*** Now test phase begins! ***\n","\tAccuracy: 0.864\n","| Test Loss: 0.324\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data.dataset import random_split\n","\n","\n","from tqdm import tqdm\n","\n","import importlib\n","\n","from datetime import datetime as dt\n","import time\n","\n","import imdb_voc\n","\n","\n","root = \"./\"\n","\n","# import sentences\n","importlib.reload(imdb_voc)\n","\n","# set device\n","dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\"\"\"\n","\n","You can implement any necessary methods.\n","\n","\"\"\"\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, d_Q, d_K, d_V, numhead, dropout):\n","        super().__init__()\n","        self.d_Qs = []\n","        self.d_Ks = []\n","        self.d_Vs = []\n","\n","        for _ in range(numhead):\n","            self.d_Qs.append(nn.Linear(d_model, d_Q).to(dev))\n","            self.d_Ks.append(nn.Linear(d_model, d_K).to(dev))\n","            self.d_Vs.append(nn.Linear(d_model, d_V).to(dev))\n","\n","        self.d_K = d_K\n","\n","        self.join_layer = nn.Linear(d_model, d_model).to(dev)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def scaled_dot_product(self, q, k, v, src_batch_lens):\n","        softmax = nn.Softmax(dim=0)\n","        a = torch.matmul(q, k.transpose(1, 2))\n","        a = a / math.sqrt(self.d_K)\n","        a = softmax(a)\n","        a = self.dropout(a)\n","        a = torch.matmul(a, v)\n","        return a\n","\n","    def forward(self, x_Q, x_K, x_V, src_batch_lens=None):\n","        # Q2. Implement\n","        heads_list = []\n","        for lq, lk, lv in zip(\n","            self.d_Qs, self.d_Ks, self.d_Vs\n","        ):\n","            q = lq(x_Q)\n","            k = lk(x_K)\n","            v = lv(x_V)\n","            head_list = self.scaled_dot_product(q, k, v, src_batch_lens)\n","            heads_list.append(head_list)\n","\n","        out_join = torch.concat(heads_list, dim=2)\n","        out = self.join_layer(out_join)\n","        out = self.dropout(out)\n","        return out\n","\n","\n","class TF_Encoder_Block(nn.Module):\n","    def __init__(self, d_model, d_ff, numhead, dropout):\n","        super().__init__()\n","        d = int(d_model / numhead)\n","        self.Multi_head_attention = MultiHeadAttention(d_model, d, d, d, numhead, dropout)\n","        self.feed_foward_layer = nn.Sequential(\n","            nn.Linear(d_model, d_ff),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(d_ff, d_model),\n","            nn.ReLU(),\n","        ).to(dev)\n","\n","    def forward(self, x: torch.Tensor, src_batch_lens):\n","        \n","        x_Q = x.clone().to(dev)\n","        x_K = x.clone().to(dev)\n","        x_V = x.clone().to(dev)\n","        x = x + self.Multi_head_attention(x_Q, x_K, x_V, src_batch_lens)\n","\n","\n","\n","        # Q4. Implment forward function for transformer encoder block\n","        self.norm_layer = nn.LayerNorm(x.shape[1:]).to(dev)\n","        x_normalize = self.norm_layer(x)\n","\n","        x_feed_foward = self.feed_foward_layer(x_normalize)\n","\n","        self.feed_and_norm_layer = nn.LayerNorm(x_feed_foward.shape[1:]).to(dev)\n","        out = self.feed_and_norm_layer(x_feed_foward)\n","\n","       \n","        return out\n","\n","\n","\"\"\" \n","Positional encoding\n","PE(pos,2i) = sin(pos/10000**(2i/dmodel))\n","PE(pos,2i+1) = cos(pos/10000**(2i/dmodel))\n","\"\"\"\n","\n","\n","def PosEncoding(t_len, d_model):\n","    i = torch.tensor(range(d_model))\n","    pos = torch.tensor(range(t_len))\n","    POS, I = torch.meshgrid(pos, i)\n","    PE = (1 - I % 2) * torch.sin(POS / 10 ** (4 * I / d_model)) + (\n","        I % 2\n","    ) * torch.cos(POS / 10 ** (4 * (I - 1) / d_model))\n","    return PE\n","\n","\n","class TF_Encoder(nn.Module):\n","    def __init__(self, vocab_size, d_model, d_ff, numlayer, numhead, dropout):\n","        super().__init__()\n","\n","        self.numlayer = numlayer\n","        self.src_embed = nn.Embedding(\n","            num_embeddings=vocab_size, embedding_dim=d_model\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # Q5. Implement a sequence of numlayer encoder blocks\n","        self.encoder_layer = []\n","        for _ in range(numlayer):\n","            self.encoder_layer.append(TF_Encoder_Block(d_model, d_ff, numhead, dropout))\n","\n","\n","    def forward(self, x, src_batch_lens):\n","        # x.shape = (B, T_S) where B is batch size, T_S is seq length of tokens\n","        x_embed = self.src_embed(x)  # x_embed.shape = (B, T_S, d_model)\n","        x = self.dropout(x_embed)  # x.shape = (B, T_S, d_model)\n","        p_enc = PosEncoding(x.shape[1], x.shape[2]).to(\n","            dev\n","        )  # p_enc.shape = (T_S, d_model)\n","        x = x + p_enc  # x.shape = (B, T_S, d_model)\n","\n","        # Q6. Implement: forward over numlayer encoder blocks\n","        for i in self.encoder_layer:\n","            x = i(x, src_batch_lens)\n","\n","        out = x\n","        # out should be (B, T_S, d_model)\n","        return out\n","\n","\n","\"\"\"\n","\n","main model\n","\n","\"\"\"\n","\n","\n","class sentiment_classifier(nn.Module):\n","    def __init__(\n","        self,\n","        enc_input_size,\n","        enc_d_model,\n","        enc_d_ff,\n","        enc_num_layer,\n","        enc_num_head,\n","        dropout,\n","    ):\n","        super().__init__()\n","\n","        self.encoder = TF_Encoder(\n","            vocab_size=enc_input_size,\n","            d_model=enc_d_model,\n","            d_ff=enc_d_ff,\n","            numlayer=enc_num_layer,\n","            numhead=enc_num_head,\n","            dropout=dropout,\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.AdaptiveAvgPool2d((1, None)),\n","            nn.Dropout(dropout),\n","            nn.Linear(in_features=enc_d_model, out_features=enc_d_model),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(in_features=enc_d_model, out_features=1),\n","        )\n","\n","    def forward(self, x, x_lens):\n","        src_ctx = self.encoder(x, src_batch_lens=x_lens)\n","        # size should be (b,)\n","        out_logits = self.classifier(src_ctx).flatten()\n","\n","        return out_logits\n","\n","\n","\"\"\"\n","\n","datasets\n","\n","\"\"\"\n","\n","# Load IMDB dataset\n","# once you build the dataset, you can load it from file to save time\n","# to load from file, set this flag True\n","load_imdb_dataset = False\n","\n","if load_imdb_dataset:\n","    imdb_dataset = torch.load(\"imdb_dataset.pt\")\n","else:\n","    imdb_dataset = imdb_voc.IMDB_tensor_dataset()\n","    torch.save(imdb_dataset, \"imdb_dataset.pt\")\n","\n","train_dataset, test_dataset = imdb_dataset.get_dataset()\n","\n","split_ratio = 0.85\n","num_train = int(len(train_dataset) * split_ratio)\n","split_train, split_valid = random_split(\n","    train_dataset, [num_train, len(train_dataset) - num_train]\n",")\n","\n","# Set hyperparam (batch size)\n","batch_size_trn = 256\n","batch_size_val = 256\n","batch_size_tst = 256\n","\n","train_dataloader = DataLoader(\n","    split_train, batch_size=batch_size_trn, shuffle=True\n",")\n","val_dataloader = DataLoader(\n","    split_valid, batch_size=batch_size_val, shuffle=True\n",")\n","test_dataloader = DataLoader(\n","    test_dataset, batch_size=batch_size_tst, shuffle=True\n",")\n","\n","# get character dictionary\n","src_word_dict = imdb_dataset.src_stoi\n","src_idx_dict = imdb_dataset.src_itos\n","\n","SRC_PAD_IDX = src_word_dict[\"<PAD>\"]\n","\n","# show sample reviews with pos/neg sentiments\n","\n","show_sample_reviews = True\n","\n","if show_sample_reviews:\n","\n","    sample_text, sample_lab = next(iter(train_dataloader))\n","    slist = []\n","\n","    for stxt in sample_text[:4]:\n","        slist.append([src_idx_dict[j] for j in stxt])\n","\n","    for j, s in enumerate(slist):\n","        print(\"positive\" if sample_lab[j] == 1 else \"negative\")\n","        print(\" \".join([i for i in s if i != \"<PAD>\"]) + \"\\n\")\n","\n","\n","\"\"\"\n","\n","model\n","\n","\"\"\"\n","\n","enc_vocab_size = len(src_word_dict)  # counting eof, one-hot vector goes in\n","\n","# Set hyperparam (model size)\n","# examples: model & ff dim - 8, 16, 32, 64, 128, numhead, numlayer 1~4\n","\n","enc_d_model = 64\n","\n","enc_d_ff = 128\n","\n","enc_num_head = 4\n","\n","enc_num_layer = 4\n","\n","DROPOUT = 0.1\n","\n","model = sentiment_classifier(\n","    enc_input_size=enc_vocab_size,\n","    enc_d_model=enc_d_model,\n","    enc_d_ff=enc_d_ff,\n","    enc_num_head=enc_num_head,\n","    enc_num_layer=enc_num_layer,\n","    dropout=DROPOUT,\n",")\n","\n","model = model.to(dev)\n","\n","\"\"\"\n","\n","optimizer\n","\n","\"\"\"\n","\n","# Set hyperparam (learning rate)\n","# examples: 1e-3 ~ 1e-5\n","\n","lr = 1e-3\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","\n","\"\"\"\n","\n","auxiliary functions\n","\n","\"\"\"\n","\n","\n","# get length of reviews in batch\n","def get_lens_from_tensor(x):\n","    # lens (batch, t)\n","    lens = torch.ones_like(x).long()\n","    lens[x == SRC_PAD_IDX] = 0\n","    return torch.sum(lens, dim=-1)\n","\n","\n","def get_binary_metrics(y_pred, y):\n","    # find number of TP, TN, FP, FN\n","    TP = sum(((y_pred == 1) & (y == 1)).type(torch.int32))\n","    FP = sum(((y_pred == 1) & (y == 0)).type(torch.int32))\n","    TN = sum(((y_pred == 0) & (y == 0)).type(torch.int32))\n","    FN = sum(((y_pred == 0) & (y == 1)).type(torch.int32))\n","    accy = (TP + TN) / (TP + FP + TN + FN)\n","\n","    recall = TP / (TP + FN) if TP + FN != 0 else 0\n","    prec = TP / (TP + FP) if TP + FP != 0 else 0\n","    f1 = 2 * recall * prec / (recall + prec) if recall + prec != 0 else 0\n","\n","    return accy, recall, prec, f1\n","\n","\n","\"\"\"\n","\n","train/validation\n","\n","\"\"\"\n","\n","\n","def train(model, dataloader, optimizer, criterion, clip):\n","\n","    model.train()\n","\n","    epoch_loss = 0\n","\n","    for i, batch in enumerate(dataloader):\n","\n","        src = batch[0].to(dev)\n","        trg = batch[1].float().to(dev)\n","\n","        # print('batch trg.shape', trg.shape)\n","        # print('batch src.shape', src.shape)\n","\n","        optimizer.zero_grad()\n","\n","        x_lens = get_lens_from_tensor(src).to(dev)\n","\n","        output = model(x=src, x_lens=x_lens)\n","\n","        output = output.contiguous().view(-1)\n","        trg = trg.contiguous().view(-1)\n","\n","        loss = criterion(output, trg)\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(dataloader)\n","\n","\n","def evaluate(model, dataloader, criterion):\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    epoch_accy = 0\n","    epoch_recall = 0\n","    epoch_prec = 0\n","    epoch_f1 = 0\n","\n","    with torch.no_grad():\n","        for i, batch in enumerate(dataloader):\n","\n","            src = batch[0].to(dev)\n","            trg = batch[1].float().to(dev)\n","\n","            x_lens = get_lens_from_tensor(src).to(dev)\n","\n","            output = model(x=src, x_lens=x_lens)\n","\n","            output = output.contiguous().view(-1)\n","            trg = trg.contiguous().view(-1)\n","\n","            loss = criterion(output, trg)\n","\n","            accy, recall, prec, f1 = get_binary_metrics(\n","                (output >= 0).long(), trg.long()\n","            )\n","            epoch_accy += accy\n","            epoch_recall += recall\n","            epoch_prec += prec\n","            epoch_f1 += f1\n","\n","            epoch_loss += loss.item()\n","\n","    # show accuracy\n","    print(f\"\\tAccuracy: {epoch_accy/(len(dataloader)):.3f}\")\n","\n","    return epoch_loss / len(dataloader)\n","\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs\n","\n","\n","\"\"\"\n","\n","Training loop\n","\n","\"\"\"\n","\n","N_EPOCHS = 30\n","CLIP = 1\n","\n","best_valid_loss = float(\"inf\")\n","\n","for epoch in range(N_EPOCHS):\n","\n","    start_time = time.time()\n","\n","    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, val_dataloader, criterion)\n","\n","    end_time = time.time()\n","\n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), \"model.pt\")\n","\n","    print(f\"Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s\")\n","    print(f\"\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}\")\n","\n","\"\"\"\n","\n","Test loop\n","\n","\"\"\"\n","print(\"*** Now test phase begins! ***\")\n","model.load_state_dict(torch.load(\"model.pt\"))\n","\n","test_loss = evaluate(model, test_dataloader, criterion)\n","\n","print(f\"| Test Loss: {test_loss:.3f}\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPu3VQlSUtFaU9yj6J8Q53z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}